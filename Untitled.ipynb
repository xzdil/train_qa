{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1bb55a-e964-4be1-b75d-125449ba358d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Архив успешно разархивирован.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Путь к вашему архиву .gz\n",
    "gz_file = 'dataset.gz'\n",
    "\n",
    "# Путь к файлу, в который будет извлечено содержимое архива\n",
    "extracted_file = 'dataset.jsonl'\n",
    "\n",
    "# Открываем архив .gz и извлекаем его содержимое в новый файл\n",
    "with gzip.open(gz_file, 'rb') as f_in:\n",
    "    with open(extracted_file, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"Архив успешно разархивирован.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54156931-116e-4e59-8589-826dc0cc7279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61606"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"test.jsonl\", 'r') as json_file:\n",
    "        dataset = list(json_file)\n",
    "\n",
    "def get_dataset_dict(dataset):\n",
    "    dataset_dict = {\"id\":[],\"context\": [], \"question\": [], \"answers\": {\"text\":[],\"answer_start\":[]}}\n",
    "\n",
    "    for json_str in dataset:\n",
    "        result = json.loads(json_str)\n",
    "        dataset_dict[\"id\"].append(result['id'])\n",
    "        dataset_dict[\"context\"].append(result['context'])\n",
    "        dataset_dict[\"question\"].append(result['question'])\n",
    "        dataset_dict['answers'][\"text\"].append(result['answers']['text'])\n",
    "        dataset_dict['answers'][\"answer_start\"].append(result['answers']['answer_start'])\n",
    "\n",
    "    return dataset_dict\n",
    "\n",
    "data_dict = get_dataset_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7558937-6b72-4562-adfb-9751af5ae8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForQuestionAnswering, DistilBertConfig, DistilBertTokenizerFast\n",
    "import torch\n",
    "model = DistilBertForQuestionAnswering(DistilBertConfig.from_pretrained('distilbert/distilbert-base-multilingual-cased')).to(\"cuda:0\")\n",
    "st_dict = torch.load(\"save/baseline_-f1fd3e31-0a1a-4c36-bb84-c92e103da1da/checkpoint/QazDistilBERT.pt\")\n",
    "model.load_state_dict(st_dict)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"dappyx/QazDistilbertFast-tokenizerV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f75415-ef25-429c-9031-97fb42bf8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_dataset\n",
    "val_dataset, val_dict = get_dataset(args, tokenizer,\"test.jsonl\", \"id_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866fde8e-702a-4447-af29-8b60cac26f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import utils\n",
    "\n",
    "model.eval()\n",
    "pred_dict = {}\n",
    "all_start_logits = []\n",
    "all_end_logits = []\n",
    "with torch.no_grad(), tqdm(total=len(data_loader.dataset)) as progress_bar:\n",
    "    for batch in data_loader:\n",
    "    # Setup for forward\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    batch_size = len(input_ids)\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    # Forward\n",
    "    start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "    all_start_logits.append(start_logits)\n",
    "    all_end_logits.append(end_logits)\n",
    "    progress_bar.update(batch_size)\n",
    "\n",
    "start_logits = torch.cat(all_start_logits).cpu().numpy()\n",
    "end_logits = torch.cat(all_end_logits).cpu().numpy()\n",
    "preds = util.postprocess_qa_predictions(\n",
    "    data_dict, data_loader.dataset.encodings, (start_logits, end_logits)\n",
    ")\n",
    "\n",
    "results = util.eval_dicts(data_dict, preds)\n",
    "results_list = [(\"F1\", results[\"F1\"]), (\"EM\", results[\"EM\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bb865-c77e-4614-bdf9-7ad857c220a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
